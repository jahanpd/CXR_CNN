{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 19:53:02.644839 139737634625344 deprecation_wrapper.py:119] From /home/jahan/Documents/CXR_CNN/algorithms/autoencoder.py:11: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223414\n",
      "191027\n",
      "CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\n",
      "<tf.Tensor: id=1, shape=(), dtype=string, numpy=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x...\n",
      "(320, 389, 1)\n",
      "<dtype: 'uint8'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from algorithms.CNN import convNN as conv\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "path = \"/media/jahan/solo/\"\n",
    "os.chdir(path)\n",
    "\n",
    "labels = pd.read_csv(\"CheXpert-v1.0-small/train.csv\")\n",
    "print(len(labels))\n",
    "labels = labels[labels[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "all_image_paths = labels.Path.values\n",
    "\n",
    "labels = [1 if x == 1 else 0 for x in labels[\"No Finding\"]]\n",
    "\n",
    "img_path = all_image_paths[0]\n",
    "print(img_path)\n",
    "\n",
    "img_raw = tf.io.read_file(img_path)\n",
    "print(repr(img_raw)[:100]+\"...\")\n",
    "img_tensor = tf.image.decode_jpeg(img_raw,channels=1)\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [256, 256])\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path): # load from path and return tensor\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = all_image_paths[0]\n",
    "label = labels[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path).numpy())\n",
    "plt.grid(False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 20:48:22.643981 140102162777920 deprecation_wrapper.py:119] From /home/jahan/Documents/CXR_CNN/algorithms/autoencoder.py:11: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223414\n",
      "191027\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jahan/miniconda3/envs/cxr/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 16) 416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "12c (BatchNormalization)        (None, 256, 256, 16) 64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 16) 0           12c[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 128, 128, 16) 272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 128, 128, 16) 64          res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 16) 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 128, 128, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 128, 128, 16) 64          res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 16) 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 128, 128, 32) 544         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 128, 128, 32) 544         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 32) 0           bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 128, 128, 32) 128         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 32) 0           activation_3[0][0]               \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 128, 128, 32) 1056        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 128, 128, 32) 9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 128, 128, 32) 1056        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           activation_7[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 128, 128, 32) 1056        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128, 32) 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 128, 128, 32) 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 128, 32) 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 128, 128, 32) 1056        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 32) 0           bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 32) 0           activation_11[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 63, 63, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 32)   1056        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 32)   128         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 32)   0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 32)   9248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 32)   128         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 32)   0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 64)   2112        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 64)   2112        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 64)   0           bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 64)   256         res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           activation_15[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 64)   4160        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 64)   4160        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           activation_19[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 64)   4160        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 64)   4160        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           activation_23[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            130         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 135,490\n",
      "Trainable params: 133,730\n",
      "Non-trainable params: 1,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from algorithms.CNN import convNN as conv\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "\n",
    "path = \"/media/jahan/solo/\"\n",
    "os.chdir(path)\n",
    "\n",
    "labels = pd.read_csv(\"CheXpert-v1.0-small/train.csv\")\n",
    "print(len(labels))\n",
    "labels = labels[labels[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "all_image_paths = labels.Path.values\n",
    "\n",
    "labels = [1 if x == 1 else 0 for x in labels[\"No Finding\"]]\n",
    "encode = onehot()\n",
    "\n",
    "labels = encode.fit_transform(np.array(labels).reshape((-1,1))).toarray()\n",
    "print(labels[:5])\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "save_path = \"/home/jahan/Documents/CXR_CNN/output/\"\n",
    "\n",
    "\n",
    "resnet = conv(image_paths=all_image_paths, labels=labels, save_path=save_path)\n",
    "resnet.build_dataset(batch_size=32)\n",
    "resnet.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 20:48:34.276372 140102162777920 deprecation.py:323] From /home/jahan/miniconda3/envs/cxr/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1240s 248ms/step - loss: 0.2393 - auc: 0.9630 - false_negatives: 13768.0000 - false_positives: 13768.0000 - true_negatives: 146232.0000 - true_positives: 146232.0000\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 1153s 231ms/step - loss: 0.2467 - auc: 0.9618 - false_negatives: 15007.0000 - false_positives: 15007.0000 - true_negatives: 144980.0000 - true_positives: 144980.0000\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 743s 149ms/step - loss: 0.2368 - auc: 0.9647 - false_negatives: 14372.0000 - false_positives: 14372.0000 - true_negatives: 145615.0000 - true_positives: 145615.0000\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 698s 140ms/step - loss: 0.2256 - auc: 0.9677 - false_negatives: 13601.0000 - false_positives: 13601.0000 - true_negatives: 146386.0000 - true_positives: 146386.0000\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 701s 140ms/step - loss: 0.2244 - auc: 0.9681 - false_negatives: 13634.0000 - false_positives: 13634.0000 - true_negatives: 146353.0000 - true_positives: 146353.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6bf7f48910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 05:33:53.363185 140207692703552 deprecation_wrapper.py:119] From /home/jahan/Documents/CXR_CNN/algorithms/autoencoder.py:11: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223414\n",
      "191027\n",
      "234\n",
      "202\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 256, 256, 16) 416         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "12c (BatchNormalization)        (None, 256, 256, 16) 64          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 256, 256, 16) 0           12c[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 128, 128, 16) 272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 128, 128, 16) 64          res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128, 128, 16) 0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 128, 128, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 128, 128, 16) 64          res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, 128, 16) 0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 128, 128, 32) 544         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 128, 128, 32) 544         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 32) 0           bn2a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 128, 128, 32) 128         res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 128, 128, 32) 0           activation_3[0][0]               \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 32) 0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 128, 128, 32) 1056        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 128, 128, 32) 9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 128, 128, 32) 1056        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 32) 0           bn2b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, 128, 32) 0           activation_7[0][0]               \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 128, 128, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 128, 128, 32) 1056        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 128, 128, 32) 0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 128, 128, 32) 9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 128, 128, 32) 0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 128, 128, 32) 1056        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 128, 128, 32) 128         res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 128, 128, 32) 0           bn2c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 128, 32) 0           activation_11[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 32) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 63, 63, 32)   0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 32, 32, 32)   1056        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 32, 32, 32)   128         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 32)   0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 32, 32, 32)   9248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 32, 32, 32)   128         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 32)   0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 32, 32, 64)   2112        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 32, 32, 64)   2112        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 64)   0           bn3a_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 32, 32, 64)   256         res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           activation_15[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 64)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 32, 32, 64)   4160        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 32, 32, 64)   4160        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 64)   0           bn3b_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           activation_19[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 32, 32, 64)   4160        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 32, 32, 64)   36928       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 32, 32, 64)   4160        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 32, 32, 64)   256         res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 64)   0           bn3c_branch2c[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           activation_23[0][0]              \n",
      "                                                                 activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 64)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            130         global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 135,490\n",
      "Trainable params: 133,730\n",
      "Non-trainable params: 1,760\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 05:33:56.104208 140207692703552 deprecation.py:323] From /home/jahan/miniconda3/envs/ml_cpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "/home/jahan/miniconda3/envs/ml_cpu/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "7/7 [==============================] - 7s 1s/step - loss: 0.2740 - auc: 0.9679 - false_negatives: 23.0000 - false_positives: 23.0000 - true_negatives: 179.0000 - true_positives: 179.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from algorithms.CNN import convNN as conv\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder as onehot\n",
    "\n",
    "\n",
    "path = \"/media/jahan/solo/\"\n",
    "os.chdir(path)\n",
    "save_path = \"/home/jahan/Documents/CXR_CNN/output/\"\n",
    "\n",
    "labels = pd.read_csv(\"CheXpert-v1.0-small/train.csv\")\n",
    "print(len(labels))\n",
    "labels = labels[labels[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "print(len(labels))\n",
    "\n",
    "labels = pd.read_csv(\"CheXpert-v1.0-small/valid.csv\")\n",
    "print(len(labels))\n",
    "labels = labels[labels[\"Frontal/Lateral\"] == \"Frontal\"]\n",
    "print(len(labels))\n",
    "\n",
    "resnet = conv(image_paths=None, labels=None, save_path=save_path)\n",
    "resnet.build(load=True)\n",
    "\n",
    "test_image_paths = labels.Path.values\n",
    "\n",
    "labels = np.array([1 if x == 1 else 0 for x in labels[\"No Finding\"]])\n",
    "encode = onehot()\n",
    "\n",
    "encoded = encode.fit_transform(labels.reshape((-1,1))).toarray()\n",
    "print(encoded[:5])\n",
    "\n",
    "metrics = resnet.predict(test_image_paths,encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9208916083916083\n",
      "[[0.2740052895886557, 0.96789527, 23.0, 23.0, 179.0, 179.0], array([[0.8511346 , 0.14886545],\n",
      "       [0.40698776, 0.5930122 ],\n",
      "       [0.9288566 , 0.07114343],\n",
      "       [0.43405095, 0.5659491 ],\n",
      "       [0.94491696, 0.05508302],\n",
      "       [0.9479595 , 0.05204051],\n",
      "       [0.6492452 , 0.35075477],\n",
      "       [0.49785712, 0.5021428 ],\n",
      "       [0.941888  , 0.05811204],\n",
      "       [0.6524254 , 0.34757462],\n",
      "       [0.6746581 , 0.32534188],\n",
      "       [0.6447982 , 0.35520175],\n",
      "       [0.9563245 , 0.0436755 ],\n",
      "       [0.7600686 , 0.23993139],\n",
      "       [0.5347908 , 0.46520913],\n",
      "       [0.98693895, 0.013061  ],\n",
      "       [0.51525515, 0.48474488],\n",
      "       [0.87541324, 0.1245868 ],\n",
      "       [0.51310545, 0.48689458],\n",
      "       [0.5598005 , 0.44019955],\n",
      "       [0.8312715 , 0.16872844],\n",
      "       [0.64630026, 0.35369974],\n",
      "       [0.5977482 , 0.40225175],\n",
      "       [0.57623994, 0.42376006],\n",
      "       [0.77261066, 0.22738935],\n",
      "       [0.88004744, 0.1199525 ],\n",
      "       [0.69331646, 0.30668357],\n",
      "       [0.6572283 , 0.34277177],\n",
      "       [0.35460797, 0.645392  ],\n",
      "       [0.9103108 , 0.08968916],\n",
      "       [0.86379254, 0.13620746],\n",
      "       [0.9346104 , 0.06538953],\n",
      "       [0.5609353 , 0.43906465],\n",
      "       [0.9251948 , 0.07480522],\n",
      "       [0.7021919 , 0.29780814],\n",
      "       [0.6484206 , 0.35157937],\n",
      "       [0.60432297, 0.39567712],\n",
      "       [0.8844787 , 0.11552127],\n",
      "       [0.70062894, 0.29937106],\n",
      "       [0.94799227, 0.05200776],\n",
      "       [0.98486984, 0.01513018],\n",
      "       [0.78928727, 0.2107128 ],\n",
      "       [0.76735806, 0.23264189],\n",
      "       [0.8985413 , 0.10145867],\n",
      "       [0.96436024, 0.03563981],\n",
      "       [0.56157655, 0.43842342],\n",
      "       [0.856438  , 0.14356205],\n",
      "       [0.7213837 , 0.27861634],\n",
      "       [0.8629046 , 0.1370954 ],\n",
      "       [0.5591789 , 0.44082117],\n",
      "       [0.8467145 , 0.15328553],\n",
      "       [0.8348797 , 0.16512032],\n",
      "       [0.43616006, 0.5638399 ],\n",
      "       [0.76149327, 0.23850672],\n",
      "       [0.7248163 , 0.27518365],\n",
      "       [0.3008591 , 0.6991409 ],\n",
      "       [0.64268935, 0.35731068],\n",
      "       [0.9026116 , 0.09738836],\n",
      "       [0.6434242 , 0.35657576],\n",
      "       [0.9499551 , 0.05004494],\n",
      "       [0.78226614, 0.21773389],\n",
      "       [0.9161867 , 0.08381333],\n",
      "       [0.8281406 , 0.17185937],\n",
      "       [0.83562386, 0.16437617],\n",
      "       [0.9514098 , 0.04859022],\n",
      "       [0.9452012 , 0.05479882],\n",
      "       [0.83295995, 0.16704002],\n",
      "       [0.7310466 , 0.2689534 ],\n",
      "       [0.78663516, 0.2133649 ],\n",
      "       [0.87238854, 0.12761146],\n",
      "       [0.9739783 , 0.02602169],\n",
      "       [0.9413832 , 0.05861688],\n",
      "       [0.91149926, 0.08850067],\n",
      "       [0.91478604, 0.08521402],\n",
      "       [0.56258404, 0.43741596],\n",
      "       [0.76219213, 0.23780788],\n",
      "       [0.6794284 , 0.3205716 ],\n",
      "       [0.8160048 , 0.18399519],\n",
      "       [0.74995995, 0.25004008],\n",
      "       [0.54745656, 0.45254347],\n",
      "       [0.8198957 , 0.18010432],\n",
      "       [0.972011  , 0.0279889 ],\n",
      "       [0.6099242 , 0.39007583],\n",
      "       [0.8914757 , 0.10852429],\n",
      "       [0.9833704 , 0.01662955],\n",
      "       [0.92441624, 0.07558372],\n",
      "       [0.7466775 , 0.2533225 ],\n",
      "       [0.85619724, 0.14380269],\n",
      "       [0.48086134, 0.51913863],\n",
      "       [0.75165486, 0.24834512],\n",
      "       [0.7291733 , 0.27082673],\n",
      "       [0.9304102 , 0.06958987],\n",
      "       [0.86813915, 0.13186084],\n",
      "       [0.8455777 , 0.15442224],\n",
      "       [0.9742113 , 0.02578871],\n",
      "       [0.8853793 , 0.1146206 ],\n",
      "       [0.9059503 , 0.0940497 ],\n",
      "       [0.89866316, 0.10133683],\n",
      "       [0.8668069 , 0.13319312],\n",
      "       [0.75498384, 0.24501617],\n",
      "       [0.9841086 , 0.01589137],\n",
      "       [0.94823456, 0.05176551],\n",
      "       [0.9427813 , 0.05721866],\n",
      "       [0.93519336, 0.06480666],\n",
      "       [0.9530836 , 0.04691643],\n",
      "       [0.9227853 , 0.07721476],\n",
      "       [0.9165896 , 0.08341042],\n",
      "       [0.82387143, 0.1761285 ],\n",
      "       [0.44245672, 0.5575433 ],\n",
      "       [0.8933009 , 0.10669909],\n",
      "       [0.9191188 , 0.08088119],\n",
      "       [0.9606645 , 0.0393355 ],\n",
      "       [0.72825795, 0.27174208],\n",
      "       [0.95740235, 0.04259762],\n",
      "       [0.8756765 , 0.12432346],\n",
      "       [0.8508786 , 0.14912136],\n",
      "       [0.94301355, 0.05698647],\n",
      "       [0.98183364, 0.01816631],\n",
      "       [0.9629436 , 0.03705637],\n",
      "       [0.6564943 , 0.34350574],\n",
      "       [0.94654995, 0.05344999],\n",
      "       [0.95321137, 0.0467886 ],\n",
      "       [0.9053658 , 0.09463423],\n",
      "       [0.5122341 , 0.48776594],\n",
      "       [0.9176349 , 0.08236512],\n",
      "       [0.9525776 , 0.04742242],\n",
      "       [0.8484294 , 0.15157057],\n",
      "       [0.92822397, 0.07177603],\n",
      "       [0.93414736, 0.06585259],\n",
      "       [0.9346662 , 0.06533378],\n",
      "       [0.97056144, 0.02943858],\n",
      "       [0.92200184, 0.0779981 ],\n",
      "       [0.9547238 , 0.04527617],\n",
      "       [0.95174724, 0.04825274],\n",
      "       [0.9099872 , 0.09001275],\n",
      "       [0.9480108 , 0.0519892 ],\n",
      "       [0.91293824, 0.08706172],\n",
      "       [0.9360669 , 0.06393304],\n",
      "       [0.8848457 , 0.11515426],\n",
      "       [0.9529687 , 0.04703125],\n",
      "       [0.9152741 , 0.08472583],\n",
      "       [0.71737236, 0.2826276 ],\n",
      "       [0.97361314, 0.02638684],\n",
      "       [0.87306833, 0.12693165],\n",
      "       [0.9716765 , 0.02832345],\n",
      "       [0.90441644, 0.0955836 ],\n",
      "       [0.49966824, 0.50033176],\n",
      "       [0.8571533 , 0.14284672],\n",
      "       [0.9463933 , 0.05360665],\n",
      "       [0.9653976 , 0.0346024 ],\n",
      "       [0.9693712 , 0.03062879],\n",
      "       [0.9537424 , 0.04625762],\n",
      "       [0.9408165 , 0.05918349],\n",
      "       [0.9622142 , 0.03778591],\n",
      "       [0.9411527 , 0.05884733],\n",
      "       [0.86096585, 0.13903412],\n",
      "       [0.7560835 , 0.24391648],\n",
      "       [0.738839  , 0.26116094],\n",
      "       [0.97167194, 0.02832809],\n",
      "       [0.89979297, 0.10020707],\n",
      "       [0.83855534, 0.16144471],\n",
      "       [0.91496664, 0.08503339],\n",
      "       [0.7304349 , 0.26956514],\n",
      "       [0.9477197 , 0.05228031],\n",
      "       [0.9593834 , 0.04061659],\n",
      "       [0.9553877 , 0.04461225],\n",
      "       [0.60749847, 0.39250153],\n",
      "       [0.7333042 , 0.2666958 ],\n",
      "       [0.6917055 , 0.3082945 ],\n",
      "       [0.7866252 , 0.2133748 ],\n",
      "       [0.69246656, 0.3075334 ],\n",
      "       [0.91360223, 0.08639774],\n",
      "       [0.9286828 , 0.07131719],\n",
      "       [0.7235887 , 0.27641127],\n",
      "       [0.8379267 , 0.16207327],\n",
      "       [0.9597495 , 0.04025052],\n",
      "       [0.98058057, 0.0194194 ],\n",
      "       [0.7068053 , 0.29319477],\n",
      "       [0.9765281 , 0.02347185],\n",
      "       [0.8730984 , 0.1269016 ],\n",
      "       [0.7999843 , 0.20001577],\n",
      "       [0.9305522 , 0.06944779],\n",
      "       [0.7202008 , 0.2797992 ],\n",
      "       [0.9332159 , 0.06678405],\n",
      "       [0.8025288 , 0.19747119],\n",
      "       [0.47083676, 0.52916324],\n",
      "       [0.8640807 , 0.13591924],\n",
      "       [0.852264  , 0.14773601],\n",
      "       [0.44557962, 0.55442035],\n",
      "       [0.78421557, 0.21578446],\n",
      "       [0.9726635 , 0.02733651],\n",
      "       [0.5946494 , 0.4053506 ],\n",
      "       [0.6966999 , 0.30330005],\n",
      "       [0.6328461 , 0.36715394],\n",
      "       [0.88962096, 0.11037899],\n",
      "       [0.7155002 , 0.28449976],\n",
      "       [0.9432199 , 0.05678013],\n",
      "       [0.852422  , 0.14757806],\n",
      "       [0.77065486, 0.22934516],\n",
      "       [0.75939417, 0.24060582],\n",
      "       [0.5888239 , 0.4111761 ],\n",
      "       [0.9281974 , 0.07180259]], dtype=float32)]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score as auc\n",
    "\n",
    "print(auc(encoded, metrics[1]))\n",
    "print(metrics)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
